{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import editdistance\n",
    "\n",
    "\n",
    "def max_flow(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        ss_weight, _ = nx.maximum_flow(G, current_node, destination)\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight\n",
    "\n",
    "def min_cost_max_flow(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        mincostFlow = nx.max_flow_min_cost(G, current_node, destination)\n",
    "        ss_weight = nx.cost_of_flow(G, mincostFlow)\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def levenshtein(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        ss_weight = editdistance.eval(curr, dest)\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight\n",
    "\n",
    "def jaccard_coefficient(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        denominator = len(curr)+len(dest)\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = len(set(curr+dest))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def common_neighbors(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        ss_weight = len(set(curr+dest))\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def lhn_index(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        denominator = len(curr)*len(dest)\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = len(set(curr+dest))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def preferential_attachment(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        ss_weight = len(curr) * len(dest)\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def hub_promoted(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        denominator = min(len(curr),len(dest))\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = len(set(curr+dest))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def hub_depressed(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        denominator = max(len(curr),len(dest))\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = len(set(curr+dest))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def salton_index(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        denominator = math.sqrt(len(curr)*len(dest))\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = len(set(curr+dest))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def sorenson_index(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        denominator = len(curr)+len(dest)\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = 2*len(set(curr+dest))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight \n",
    "\n",
    "def tversky(G, current_node, destination):\n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        a = set(curr)\n",
    "        b = set(dest)\n",
    "        union = a.union(b)\n",
    "        a_compl = a.difference(b)\n",
    "        b_compl = b.difference(a)\n",
    "        denominator = len(union) + len(curr)*len(a_compl)+len(dest)*len(b_compl)\n",
    "        if denominator == 0:\n",
    "            ss_weight = 0\n",
    "        else:\n",
    "            numerator = len(a.intersection(b))\n",
    "            ss_weight = numerator/denominator\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight\n",
    "\n",
    "def adamic_adar(G, current_node, destination):\n",
    "    def calc_weight(node):\n",
    "        denominator = math.log10(len(list(G.neighbors(node))))\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 / denominator\n",
    "        \n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        intersection = set(curr+dest)\n",
    "        adamic_adar_indices = sum([calc_weight(node) for node in intersection])\n",
    "        ss_weight = adamic_adar_indices\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight\n",
    "\n",
    "def resource_allocation(G, current_node, destination, num_jobs=-1):\n",
    "    def calc_weight(node):\n",
    "        denominator = len(list(G.neighbors(node)))\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 / denominator\n",
    "        \n",
    "    if current_node != destination:\n",
    "        curr = list(G.neighbors(current_node))\n",
    "        dest = list(G.neighbors(destination))\n",
    "        intersection = set(curr+dest)\n",
    "        resource_allocation_indices = sum([calc_weight(node) for node in intersection])\n",
    "        ss_weight = resource_allocation_indices\n",
    "    else:\n",
    "        ss_weight = 0\n",
    "    return ss_weight\n",
    "\n",
    "def generate_walks_for_node(node, num_walks, walk_length, probs):\n",
    "    node_walks = []\n",
    "    for walk in range(num_walks):\n",
    "        walk_list = [node]\n",
    "        for step in range(walk_length - 1):\n",
    "            neighbors = list(probs[walk_list[-1]].keys())\n",
    "            probabilities = list(probs[walk_list[-1]].values())\n",
    "            next_node = np.random.choice(neighbors, p=probabilities)\n",
    "            walk_list.append(next_node)\n",
    "        node_walks.append(walk_list)\n",
    "    return node_walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import networkx as nx\n",
    "import gensim\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from wirewalk.core import generate_walks_for_node\n",
    "\n",
    "class WireWalk():\n",
    "    def __init__(self, graph: nx.Graph, dimensions: int = 128, window: int = 10, \n",
    "                walk_length: int = 80, num_walks: int = 10, \n",
    "                workers: int = 1):\n",
    "        self.graph = graph\n",
    "        self.dimensions = dimensions\n",
    "        self.window = window\n",
    "        self.walk_length = walk_length\n",
    "        self.num_walks = num_walks\n",
    "        self.workers = workers\n",
    "    \n",
    "    def generate_transition(self, transition_matrix_function):\n",
    "        G = self.graph\n",
    "        nodes = G.nodes\n",
    "        pool = mp.Pool()\n",
    "\n",
    "        params = []\n",
    "        for current_node in nodes:\n",
    "            for destination in nodes:\n",
    "                params.append((G,current_node, destination))\n",
    "\n",
    "        ss_weights = pool.starmap(transition_matrix_function, params)\n",
    "        # close the process pool\n",
    "        pool.close()\n",
    "        # wait for all tasks to complete\n",
    "        pool.join()\n",
    "\n",
    "        ss_weights_matrix1 = np.reshape(ss_weights, (len(nodes), len(nodes)))\n",
    "        row_sums = ss_weights_matrix1.sum(axis=1)\n",
    "        zero_rows = np.where(row_sums == 0)[0]\n",
    "        ss_weights_matrix1[zero_rows, :] = 0\n",
    "        for i in zero_rows:\n",
    "            ss_weights_matrix1[i, i] = 1\n",
    "        row_sums = ss_weights_matrix1.sum(axis=1)\n",
    "        ss_weights_matrix1 = np.divide(ss_weights_matrix1, row_sums[:, np.newaxis])\n",
    "        return ss_weights_matrix1\n",
    "\n",
    "    def generate_walks(self, transition_probs):\n",
    "        graph = self.graph\n",
    "        num_walks = self.num_walks\n",
    "        walk_length = self.walk_length\n",
    "\n",
    "        walks = []\n",
    "        nodes = list(graph.nodes())\n",
    "        probs = {}\n",
    "        for i, node_i in enumerate(nodes):\n",
    "            probs[node_i] = {}\n",
    "            for j, node_j in enumerate(nodes):\n",
    "                probs[node_i][node_j] = transition_probs[i][j]\n",
    "\n",
    "        params = []\n",
    "        for node in nodes:\n",
    "            params.append((node, num_walks, walk_length, probs))\n",
    "\n",
    "        pool = mp.Pool()\n",
    "        node_walks_list = pool.starmap(generate_walks_for_node, params)\n",
    "        # close the process pool\n",
    "        pool.close()\n",
    "        # wait for all tasks to complete\n",
    "        pool.join()\n",
    "\n",
    "        for node_walks in node_walks_list:\n",
    "            walks += node_walks\n",
    "            \n",
    "        return walks\n",
    "\n",
    "    def fit(self, transformation: callable) -> gensim.models.Word2Vec:\n",
    "        transition_probability_matrix = self.generate_transition(transformation)\n",
    "        walks = self.generate_walks(transition_probability_matrix)\n",
    "        return gensim.models.Word2Vec(walks,window=self.window, workers=self.workers, vector_size=self.dimensions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
