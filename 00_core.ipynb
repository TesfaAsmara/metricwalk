{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import gensim\n",
    "\n",
    "class MetricWalk:\n",
    "    def __init__(self, graph: nx.Graph, dimensions: int = 128, window: int = 10, \n",
    "                 walk_length: int = 80, num_walks: int = 10, \n",
    "                 workers: int = 1):\n",
    "        self.graph = graph\n",
    "        self.dimensions = dimensions\n",
    "        self.window = window\n",
    "        self.walk_length = walk_length\n",
    "        self.num_walks = num_walks\n",
    "        self.workers = workers\n",
    "\n",
    "    def jaccard_coefficient(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            denominator = len(curr)+len(dest)\n",
    "            if denominator == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                numerator = len(set(curr+dest))\n",
    "                score = numerator/denominator\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def adamic_adar(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        num_jobs = self.workers\n",
    "        def calc_weight(node):\n",
    "            denominator = math.log10(len(list(G.neighbors(node))))\n",
    "            if denominator == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1 / denominator\n",
    "            \n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            intersection = set(curr+dest)\n",
    "            \n",
    "            adamic_adar_indices = sum(Parallel(n_jobs=num_jobs)(\n",
    "                delayed(calc_weight)(node) for node in intersection\n",
    "            ))\n",
    "            \n",
    "            score = adamic_adar_indices\n",
    "        else:\n",
    "            score = 0\n",
    "        return score\n",
    "\n",
    "    def common_neighbors(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            score = len(set(curr+dest))\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def lhn_index(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            denominator = len(curr)*len(dest)\n",
    "            if denominator == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                numerator = len(set(curr+dest))\n",
    "                score = numerator/denominator\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def preferential_attachment(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            score = len(curr) * len(dest)\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def hub_promoted(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            denominator = min(len(curr),len(dest))\n",
    "            if denominator == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                numerator = len(set(curr+dest))\n",
    "                score = numerator/denominator\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def hub_depressed(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            denominator = max(len(curr),len(dest))\n",
    "            if denominator == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                numerator = len(set(curr+dest))\n",
    "                score = numerator/denominator\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def salton_index(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            denominator = math.sqrt(len(curr)*len(dest))\n",
    "            if denominator == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                numerator = len(set(curr+dest))\n",
    "                score = numerator/denominator\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def sorenson_index(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            denominator = len(curr)+len(dest)\n",
    "            if denominator == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                numerator = 2*len(set(curr+dest))\n",
    "                score = numerator/denominator\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def resource_allocation(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        num_jobs = self.workers\n",
    "        def calc_weight(node):\n",
    "            denominator = len(list(G.neighbors(node)))\n",
    "            if denominator == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1 / denominator\n",
    "            \n",
    "        if current_node != destination:\n",
    "            curr = list(G.neighbors(current_node))\n",
    "            dest = list(G.neighbors(destination))\n",
    "            intersection = set(curr+dest)\n",
    "            \n",
    "            resource_allocation_indices = sum(Parallel(n_jobs=num_jobs)(\n",
    "                delayed(calc_weight)(node) for node in intersection\n",
    "            ))\n",
    "            \n",
    "            score = resource_allocation_indices\n",
    "        else:\n",
    "            score = 0\n",
    "        return score\n",
    "\n",
    "    def max_flow(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            score, _ = nx.maximum_flow(G, current_node, destination)\n",
    "        else:\n",
    "            score = 0\n",
    "        return score\n",
    "\n",
    "    def min_cost_max_flow(self, current_node, destination):\n",
    "        G = self.graph\n",
    "        if current_node != destination:\n",
    "            mincostFlow = nx.max_flow_min_cost(G, current_node, destination)\n",
    "            score = nx.cost_of_flow(G, mincostFlow)\n",
    "        else:\n",
    "            score = 0\n",
    "        return score \n",
    "\n",
    "    def generate_transition(self, transition_matrix_function):\n",
    "        G = self.graph\n",
    "        nodes = G.nodes\n",
    "        num_workers = self.workers\n",
    "        # Split the nodes into chunks for each worker\n",
    "        node_chunks = np.array_split(nodes, num_workers)\n",
    "\n",
    "        # Use joblib to parallelize the calculation of ss_weight\n",
    "        scores = Parallel(n_jobs=num_workers)(\n",
    "            delayed(transition_matrix_function)(current_node, destination)\n",
    "            for chunk in node_chunks\n",
    "            for current_node in chunk\n",
    "            for destination in nodes\n",
    "        )\n",
    "\n",
    "        # Reshape the unnormalized scores into an unnormalized transition probability matrix\n",
    "        unnormalized_transition = np.reshape(scores, (len(nodes), len(nodes)))\n",
    "\n",
    "\n",
    "        # check if row sums are zero\n",
    "        row_sums = unnormalized_transition.sum(axis=1)\n",
    "        zero_rows = np.where(row_sums == 0)[0]\n",
    "\n",
    "        # set all elements in zero rows to zero, except for diagonal element\n",
    "        unnormalized_transition[zero_rows, :] = 0\n",
    "        for i in zero_rows:\n",
    "            unnormalized_transition[i, i] = 1\n",
    "\n",
    "        row_sums = unnormalized_transition.sum(axis=1)\n",
    "\n",
    "        # normalize matrix by row sums\n",
    "        normalized_transition = np.divide(unnormalized_transition, row_sums[:, np.newaxis])\n",
    "        return normalized_transition\n",
    "\n",
    "    def generate_walks(self, transition_probs):\n",
    "        graph = self.graph\n",
    "        num_walks = self.num_walks\n",
    "        walk_length = self.walk_length\n",
    "        num_jobs = self.workers \n",
    "        walks = []\n",
    "        nodes = list(graph.nodes())\n",
    "\n",
    "        # Convert the transition probabilities to a dictionary of dictionaries for faster access\n",
    "        probs = {}\n",
    "        for i, node_i in enumerate(nodes):\n",
    "            probs[node_i] = {}\n",
    "            for j, node_j in enumerate(nodes):\n",
    "                probs[node_i][node_j] = transition_probs[i][j]\n",
    "\n",
    "        def generate_walks_for_node(node):\n",
    "            node_walks = []\n",
    "            for walk in range(num_walks):\n",
    "                walk_list = [node]\n",
    "                for step in range(walk_length - 1):\n",
    "                    neighbors = list(probs[walk_list[-1]].keys())\n",
    "                    probabilities = list(probs[walk_list[-1]].values())\n",
    "                    next_node = np.random.choice(neighbors, p=probabilities)\n",
    "                    walk_list.append(next_node)\n",
    "                node_walks.append(walk_list)\n",
    "            return node_walks\n",
    "\n",
    "        node_walks_list = Parallel(n_jobs=num_jobs)(\n",
    "            delayed(generate_walks_for_node)(node) for node in nodes)\n",
    "\n",
    "        for node_walks in node_walks_list:\n",
    "            walks += node_walks\n",
    "\n",
    "        return walks\n",
    "\n",
    "    def fit(self, transformation: callable) -> gensim.models.Word2Vec:\n",
    "        transition_probability_matrix = self.generate_transition(transformation)\n",
    "        walks = self.generate_walks(transition_probability_matrix)\n",
    "        return gensim.models.Word2Vec(walks,window=self.window, workers=self.workers, vector_size=self.dimensions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
